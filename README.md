# Awesome-training-free-diffusion

## Contents

## Image synthesis

**Training-free diffusion model adaptation for variable-sized text-to-image synthesis** \
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/e0378e0c642b1d292fcb224e8d5a39b3-Paper-Conference.pdf)]

**Brush Your Text: Synthesize Any Scene Text on Images via Diffusion Model** \
[[Github](https://github.com/ecnuljzhang/brush-your-text)]
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/28550/29069)]

**Enhancing Prompt Following with Visual Control Through Training-Free Mask-Guided Diffusion** \
[[Paper](https://arxiv.org/pdf/2404.14768)]

**Training-Free Consistent Text-to-Image Generation** \
[[Github](https://consistory-paper.github.io/)]
[[Paper](https://arxiv.org/abs/2402.03286)]

**Boundary Guided Learning-Free Semantic Control with Diffusion Models** \
[[Github](https://l-yezhu.github.io/BoundaryDiffusion/)]
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/f737da5ea0e122870fad209509f87d5b-Paper-Conference.pdf)]

**LoRA-Composer: Leveraging Low-Rank Adaptation for Multi-Concept Customization in Training-Free Diffusion Models** \
[[Github](https://github.com/Young98CN/LoRA_Composer)]
[[Paper](https://arxiv.org/pdf/2403.11627)]

**A Training-Free Plug-and-Play Watermark Framework For Stable Diffusion** \
[[Paper](https://arxiv.org/pdf/2404.05607)]

**BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion** \
[[Github](https://github.com/showlab/BoxDiff)]
[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.pdf)]

**FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model** \
[[Github](https://github.com/vvictoryuki/FreeDoM)]
[[Paper](https://arxiv.org/pdf/2303.09833)]

## Diffusion Model Acceleration

**AutoDiffusion: Training-Free Optimization of Time Steps and Architectures for Automated Diffusion Model Acceleration** \
[[Github](https://github.com/lilijiangg/AutoDiffusion)]
[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.pdf)]

## Segmentation
**FreeSeg-Diff: Training-Free Open-Vocabulary Segmentation with Diffusion Models** \
[[Github](https://bcorrad.github.io/freesegdiff/)]
[[Paper](https://arxiv.org/pdf/2403.20105)]


## Image Edit

**Training-free Content Injection using h-space in Diffusion Models** \
[[Github](https://curryjung.github.io/DiffStyle/)]
[[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Jeong_Training-Free_Content_Injection_Using_H-Space_in_Diffusion_Models_WACV_2024_paper.pdf)]

**Prompt-to-Prompt Image Editing with Cross Attention Control** \
[[Github](https://github.com/google/prompt-to-prompt)]
[[Paper])(https://arxiv.org/pdf/2208.01626)]

## Image Translation

**Zero-shot Image-to-Image Translation** \
[[Github](https://github.com/pix2pixzero/pix2pix-zero)]
[[Paper](https://arxiv.org/pdf/2302.03027)]




