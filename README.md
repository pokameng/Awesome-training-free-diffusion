# Awesome-training-free-diffusion

## Contents

## Image synthesis

**Training-free diffusion model adaptation for variable-sized text-to-image synthesis** \
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/e0378e0c642b1d292fcb224e8d5a39b3-Paper-Conference.pdf)]

**Brush Your Text: Synthesize Any Scene Text on Images via Diffusion Model** \
[[Github](https://github.com/ecnuljzhang/brush-your-text)]
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/28550/29069)]

**Enhancing Prompt Following with Visual Control Through Training-Free Mask-Guided Diffusion** \
[[Paper](https://arxiv.org/pdf/2404.14768)]

**Training-Free Consistent Text-to-Image Generation** \
[[Github](https://consistory-paper.github.io/)]
[[Paper](https://arxiv.org/abs/2402.03286)]

**Boundary Guided Learning-Free Semantic Control with Diffusion Models** \
[[Github](https://l-yezhu.github.io/BoundaryDiffusion/)]
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/f737da5ea0e122870fad209509f87d5b-Paper-Conference.pdf)]

**LoRA-Composer: Leveraging Low-Rank Adaptation for Multi-Concept Customization in Training-Free Diffusion Models** \
[[Github](https://github.com/Young98CN/LoRA_Composer)]
[[Paper](https://arxiv.org/pdf/2403.11627)]

**A Training-Free Plug-and-Play Watermark Framework For Stable Diffusion** \
[[Paper](https://arxiv.org/pdf/2404.05607)]

**BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion** \
[[Github](https://github.com/showlab/BoxDiff)]
[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.pdf)]

**BOX IT TO BIND IT: UNIFIED LAYOUT CONTROL AND ATTRIBUTE BINDING IN T2I DIFFUSION MODELS** \
[[Github](https://github.com/nextaistudio/BoxIt2BindIt)]
[[Paper](https://arxiv.org/pdf/2402.17910)]

**FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model** \
[[Github](https://github.com/vvictoryuki/FreeDoM)]
[[Paper](https://arxiv.org/pdf/2303.09833)]

**Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs** \
[[Github](https://github.com/YangLing0818/RPG-DiffusionMaster)]
[[Paper](https://arxiv.org/pdf/2401.11708v2)]

**MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion** \
[[Github](https://github.com/measure-infinity/mulan-code)]
[[Paper](https://arxiv.org/pdf/2402.12741)]

**MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis** \
[[Github](https://migcproject.github.io/)]
[[Paper](https://arxiv.org/pdf/2402.05408)]

**TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition** \
[[Github](https://github.com/Shilin-LU/TF-ICON)]
[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.pdf)]

**DIFFUSION IN DIFFUSION: CYCLIC ONE-WAY DIFFUSION FOR TEXT-VISION-CONDITIONED GENERATION** \
[[Github](https://wangruoyu02.github.io/cow.github.io/)]
[[Paper](https://arxiv.org/pdf/2306.08247)]

**RealCompo: Dynamic Equilibrium between Realism and Compositionality Improves Text-to-Image Diffusion Models** \
[[Github](https://github.com/YangLing0818/RealCompo)]
[[Paper](https://arxiv.org/pdf/2402.12908v1)]

**Shape-Guided Diffusion with Inside-Outside Attention** \
[[Github](https://shape-guided-diffusion.github.io/)]
[[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Park_Shape-Guided_Diffusion_With_Inside-Outside_Attention_WACV_2024_paper.pdf)]

**FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion Models** \
[[Github](https://freestylefreelunch.github.io/)]
[[Paper](https://arxiv.org/pdf/2401.15636v1)]

**Prompt-Free Diffusion: Taking “Text” out of Text-to-Image Diffusion Models**
[[Github](https://github.com/SHI-Labs/Prompt-Free-Diffusion)]
[[Paper](https://arxiv.org/pdf/2305.16223)]

**Training-free Diffusion Model Adaptation for Variable-Sized Text-to-Image Synthesis**
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/e0378e0c642b1d292fcb224e8d5a39b3-Paper-Conference.pdf)]

**FreeTuner: Any Subject in Any Style with Training-free Diffusion**
[[Paper](https://arxiv.org/pdf/2405.14201)]

## Diffusion Model Acceleration

**AutoDiffusion: Training-Free Optimization of Time Steps and Architectures for Automated Diffusion Model Acceleration** \
[[Github](https://github.com/lilijiangg/AutoDiffusion)]
[[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.pdf)]

**SEEDS: Exponential SDE Solvers for Fast High-Quality Sampling from Diffusion Models** \
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/d6f764aae383d9ff28a0f89f71defbd9-Paper-Conference.pdf)]

**DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics** \
[[Github](https://github.com/thu-ml/DPM-Solver-v3)]
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/ada8de994b46571bdcd7eeff2d3f9cff-Paper-Conference.pdf)]

## Segmentation
**FreeSeg-Diff: Training-Free Open-Vocabulary Segmentation with Diffusion Models** \
[[Github](https://bcorrad.github.io/freesegdiff/)]
[[Paper](https://arxiv.org/pdf/2403.20105)]


## Image Edit

**Training-free Content Injection using h-space in Diffusion Models** \
[[Github](https://curryjung.github.io/DiffStyle/)]
[[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Jeong_Training-Free_Content_Injection_Using_H-Space_in_Diffusion_Models_WACV_2024_paper.pdf)]

**Prompt-to-Prompt Image Editing with Cross Attention Control** \
[[Github](https://github.com/google/prompt-to-prompt)]
[[Paper](https://arxiv.org/pdf/2208.01626)]

**ObjectAdd: Adding Objects into Image via a Training-Free Diffusion Modification Fashion** \
[[Github](https://github.com/potato-kitty/ObjectAdd)]
[[Paper](https://arxiv.org/pdf/2404.17230)]

## Image Translation

**Zero-shot Image-to-Image Translation** \
[[Github](https://github.com/pix2pixzero/pix2pix-zero)]
[[Paper](https://arxiv.org/pdf/2302.03027)]

## Video Translation
**FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation** \
[[Github](https://github.com/williamyang1991/FRESCO)]
[[Paper](https://arxiv.org/pdf/2403.12962)]

## Video Generation
**ControlVideo: Training-free Controllable Text-to-Video Generation** \
[[Github](https://github.com/YBYBZhang/ControlVideo)]
[[Paper](https://arxiv.org/pdf/2305.13077)]

**FLATTEN: OPTICAL FLOW-GUIDED ATTENTION FOR CONSISTENT TEXT-TO-VIDEO EDITING** \
[[Github](https://flatten-video-editing.github.io/)]
[[Paper](https://arxiv.org/pdf/2310.05922)]

**FREENOISE: TUNING-FREE LONGER VIDEO DIFFUSION VIA NOISE RESCHEDULING**
[[Github](http://haonanqiu.com/projects/FreeNoise.html)]
[[Paper](https://arxiv.org/pdf/2310.15169)]

**FIFO-Diffusion: Generating Infinite Videos from Text without Training**
[[Github](https://jjihwan.github.io/projects/FIFO-Diffusion)]
[[Paper](https://arxiv.org/pdf/2405.11473)]




